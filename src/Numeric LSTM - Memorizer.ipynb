{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric LSTM\n",
    "=====\n",
    "\n",
    "Essa é a implementação de uma LSTM memorizar uma representação de números de vários algarismos. Números são lidos um dígito de cada vez, de modo que a LSTM aprenda uma representação interna para quantidades. Em seguida, uma outra LSTM decodifica a célula de memória, gerando os números originais.\n",
    "\n",
    "Funcionamento geral\n",
    "----\n",
    "\n",
    "1. LSTM encoder codifica a sequência de números.\n",
    "\n",
    "2. LSTM decoder gera a saída, um algarismo de cada vez (é aplicado um softmax sobre a saída da rede)\n",
    "\n",
    "Obs:\n",
    "\n",
    "- Embeddings são compartilhadas, mas o encoder e decoder têm seus próprios parâmetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a number with 8 digits most and END\n",
    "output_sequence_size = 9\n",
    "\n",
    "# digits 0-9\n",
    "encoder_vocab = 10\n",
    "\n",
    "# digits 0-9, GO and END symbols\n",
    "decoder_vocab = 12\n",
    "\n",
    "# digits 0-9, GO and END symbols\n",
    "vocab_size = 12\n",
    "\n",
    "class Symbol(object):\n",
    "    \"\"\"\n",
    "    Placeholder class for values used in the RNNs.\n",
    "    \"\"\"\n",
    "    END = 10\n",
    "    GO = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do grafo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Código abaixo reseta o grafo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "num_lstm_units = embedding_size\n",
    "\n",
    "# a number with 8 digits plus at least one END symbol\n",
    "input_sequence_size = 9\n",
    "\n",
    "max_sample_size = 20\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "# both terms are inputs to the encoder\n",
    "first_term = tf.placeholder(tf.int32, [input_sequence_size, None], 'first_term')\n",
    "second_term = tf.placeholder(tf.int32, [input_sequence_size, None], 'second_term')\n",
    "\n",
    "first_term_size = tf.placeholder(tf.int32, [None], 'first_term_size')\n",
    "second_term_size = tf.placeholder(tf.int32, [None], 'second_term_size')\n",
    "#decoder_data = tf.placeholder(tf.int32, [output_sequence_size, None], 'results_%d' % i)\n",
    "\n",
    "# we want to share the embeddings between encoder and decoder, but not all parameters\n",
    "shape = [vocab_size, embedding_size]\n",
    "embeddings = tf.Variable(tf.random_uniform(shape, -1.0, 1.0), name='embeddings')\n",
    "\n",
    "lstm_initializer = tf.random_uniform_initializer(-0.1, 0.1)\n",
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(num_lstm_units, embedding_size, \n",
    "                                    initializer=lstm_initializer)\n",
    "\n",
    "with tf.variable_scope('output_softmax') as softmax_scope:\n",
    "    # softmax to map decoder raw output to digits\n",
    "    shape = [num_lstm_units, vocab_size]\n",
    "    softmax_weights = tf.Variable(tf.truncated_normal(shape, 0.0, 0.1))\n",
    "    softmax_bias = tf.Variable(tf.zeros([vocab_size]))    \n",
    "\n",
    "def generate_rnn_input(sequence_indices, num_time_steps):\n",
    "    \"\"\"\n",
    "    Generate the input to the RNN from a tensor of shape [sequence_size, batch_size]\n",
    "    Return a list of tensors of shape [batch_size, embedding_size]\n",
    "    \"\"\"\n",
    "    embedded_sequence =  tf.nn.embedding_lookup(embeddings, sequence_indices)\n",
    "    return [tf.squeeze(time_step, [0]) \n",
    "            for time_step in tf.split(0, num_time_steps, embedded_sequence)]\n",
    "    \n",
    "\n",
    "input_1st_term = generate_rnn_input(first_term, input_sequence_size)\n",
    "\n",
    "with tf.variable_scope('encoder') as encoder_scope:\n",
    "    _, state_1st_term = tf.nn.rnn(lstm_cell, input_1st_term, \n",
    "                                  sequence_length=first_term_size, dtype=tf.float32)\n",
    "    #scope.reuse_variables()\n",
    "    #_, state_2nd_term = tf.nn.rnn(lstm_cell, input_2nd_term, dtype=tf.float32)\n",
    "\n",
    "# create a tensor of 1's with the batch size and then multiply it by the GO embedding\n",
    "embedded_go = tf.nn.embedding_lookup(embeddings, Symbol.GO)\n",
    "batch_go = tf.ones_like(input_1st_term[0]) * embedded_go\n",
    "\n",
    "input_as_list = [tf.squeeze(time_step)\n",
    "                 for time_step in tf.split(0, input_sequence_size, first_term)]\n",
    "\n",
    "decoder_inputs = [batch_go] + input_1st_term[:-1]\n",
    "decoder_labels = input_as_list\n",
    "\n",
    "# label_weights is just used to weight the importance of each class\n",
    "label_weights = [tf.ones_like(decoder_labels[0], dtype=tf.float32)\n",
    "                 for _ in decoder_labels]\n",
    "\n",
    "with tf.variable_scope('decoder') as decoder_scope:\n",
    "    raw_outputs, _ = tf.nn.seq2seq.rnn_decoder(decoder_inputs, state_1st_term, \n",
    "                                               lstm_cell)\n",
    "\n",
    "def project_output(raw_outputs, return_softmax=False):\n",
    "    \"\"\"\n",
    "    Multiply the raw_outputs by a weight matrix, add a bias and return the\n",
    "    softmax distribution or the logits.\n",
    "    \n",
    "    :param return_softmax: if True, return the softmaxes. If False, return\n",
    "        the logits\n",
    "    \"\"\"\n",
    "    output_logits = [tf.nn.xw_plus_b(time_step, softmax_weights, softmax_bias)\n",
    "                     for time_step in raw_outputs]\n",
    "    if not return_softmax:\n",
    "        return output_logits\n",
    "    \n",
    "    output_softmax = [tf.nn.softmax(time_step) for time_step in output_logits]\n",
    "    return output_softmax\n",
    "\n",
    "output_logits = project_output(raw_outputs, False)\n",
    "loss = tf.nn.seq2seq.sequence_loss(output_logits, decoder_labels, label_weights)\n",
    "\n",
    "# evaluation\n",
    "sample_input = tf.placeholder(tf.int32, [max_sample_size, 1], name='sample_input')\n",
    "sample_size = tf.placeholder(tf.int32, 1, name='sample_size')\n",
    "\n",
    "#embedded_sample = tf.nn.embedding_lookup(embeddings, sample_input)\n",
    "#embedded_sample_list = [tf.squeeze(time_step, [0]) \n",
    "#                        for time_step in tf.split(0, max_sample_size, embedded_sample)]\n",
    "sample_encoder_list_input = generate_rnn_input(sample_input, max_sample_size)\n",
    "\n",
    "with tf.variable_scope(encoder_scope, reuse=True):\n",
    "    _, sample_encoder_state = tf.nn.rnn(lstm_cell, sample_encoder_list_input, \n",
    "                                sequence_length=sample_size, dtype=tf.float32)\n",
    "\n",
    "#sample_decoder_go = tf.ones_like(sample_encoder_input[0]) * embedded_go\n",
    "sample_decoder_state = tf.placeholder(tf.float32, [1, lstm_cell.state_size], \n",
    "                                      name='sample_decoder_state')\n",
    "sample_decoder_input = tf.placeholder(tf.int32, [1, 1], name='sample_decoder_input')\n",
    "sample_decoder_list_input = generate_rnn_input(sample_decoder_input, 1)\n",
    "\n",
    "with tf.variable_scope(decoder_scope, reuse=True):\n",
    "    # in principle we could call the lstm_cell directly, since it's only one time step; \n",
    "    # however, its weights are defined under the scope of the rnn_decoder. \n",
    "    # So, calling the decoder is simpler\n",
    "    raw_sample_outputs, new_decoder_state = tf.nn.seq2seq.rnn_decoder(sample_decoder_list_input, \n",
    "                                                                      sample_decoder_state, \n",
    "                                                                      lstm_cell)\n",
    "\n",
    "sample_softmax = project_output(raw_sample_outputs, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "global_step = tf.Variable(0)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, epsilon=0.1)\n",
    "gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "\n",
    "train_op = optimizer.apply_gradients(zip(gradients, v), \n",
    "                                     global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execução\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Loss: 2.04619\n",
      "Epoch 40\n",
      "Loss: 1.02354\n",
      "Epoch 60\n",
      "Loss: 2.11340\n",
      "Epoch 80\n",
      "Loss: 0.52669\n",
      "Epoch 100\n",
      "Loss: 1.21095\n",
      "Epoch 120\n",
      "Loss: 2.45261\n",
      "Epoch 140\n",
      "Loss: 2.27681\n",
      "Epoch 160\n",
      "Loss: 1.69539\n",
      "Epoch 180\n",
      "Loss: 1.92853\n",
      "Epoch 200\n",
      "Loss: 1.63474\n",
      "Epoch 220\n",
      "Loss: 0.55691\n",
      "Epoch 240\n",
      "Loss: 0.52502\n",
      "Epoch 260\n",
      "Loss: 1.59250\n",
      "Epoch 280\n",
      "Loss: 0.70361\n",
      "Epoch 300\n",
      "Loss: 0.66664\n",
      "Epoch 320\n",
      "Loss: 0.61588\n",
      "Epoch 340\n",
      "Loss: 0.33416\n",
      "Epoch 360\n",
      "Loss: 0.47599\n",
      "Epoch 380\n",
      "Loss: 1.78752\n",
      "Epoch 400\n",
      "Loss: 1.75068\n",
      "Epoch 420\n",
      "Loss: 0.50206\n",
      "Epoch 440\n",
      "Loss: 0.45052\n",
      "Epoch 460\n",
      "Loss: 0.25359\n",
      "Epoch 480\n",
      "Loss: 1.02665\n",
      "Epoch 500\n",
      "Loss: 0.79841\n",
      "Epoch 520\n",
      "Loss: 0.08948\n",
      "Epoch 540\n",
      "Loss: 0.45765\n",
      "Epoch 560\n",
      "Loss: 0.43004\n",
      "Epoch 580\n",
      "Loss: 0.64954\n",
      "Epoch 600\n",
      "Loss: 0.06184\n",
      "Epoch 620\n",
      "Loss: 0.01829\n",
      "Epoch 640\n",
      "Loss: 0.23490\n",
      "Epoch 660\n",
      "Loss: 0.20860\n",
      "Epoch 680\n",
      "Loss: 0.11726\n",
      "Epoch 700\n",
      "Loss: 0.70820\n",
      "Epoch 720\n",
      "Loss: 0.09541\n",
      "Epoch 740\n",
      "Loss: 0.04367\n",
      "Epoch 760\n",
      "Loss: 0.15559\n",
      "Epoch 780\n",
      "Loss: 1.44031\n",
      "Epoch 800\n",
      "Loss: 0.03408\n",
      "Epoch 820\n",
      "Loss: 0.03890\n",
      "Epoch 840\n",
      "Loss: 1.24746\n",
      "Epoch 860\n",
      "Loss: 0.08195\n",
      "Epoch 880\n",
      "Loss: 0.77793\n",
      "Epoch 900\n",
      "Loss: 1.29466\n",
      "Epoch 920\n",
      "Loss: 0.11021\n",
      "Epoch 940\n",
      "Loss: 1.20692\n",
      "Epoch 960\n",
      "Loss: 0.07474\n",
      "Epoch 980\n",
      "Loss: 0.76028\n",
      "Epoch 1000\n",
      "Loss: 0.25963\n",
      "Epoch 1020\n",
      "Loss: 0.33548\n",
      "Epoch 1040\n",
      "Loss: 0.03717\n",
      "Epoch 1060\n",
      "Loss: 1.39348\n",
      "Epoch 1080\n",
      "Loss: 0.04945\n",
      "Epoch 1100\n",
      "Loss: 0.18850\n",
      "Epoch 1120\n",
      "Loss: 0.27637\n",
      "Epoch 1140\n",
      "Loss: 0.23686\n",
      "Epoch 1160\n",
      "Loss: 0.01389\n",
      "Epoch 1180\n",
      "Loss: 0.36575\n",
      "Epoch 1200\n",
      "Loss: 0.16258\n",
      "Epoch 1220\n",
      "Loss: 0.55382\n",
      "Epoch 1240\n",
      "Loss: 0.53308\n",
      "Epoch 1260\n",
      "Loss: 0.77499\n",
      "Epoch 1280\n",
      "Loss: 1.18168\n",
      "Epoch 1300\n",
      "Loss: 0.07259\n",
      "Epoch 1320\n",
      "Loss: 0.00863\n",
      "Epoch 1340\n",
      "Loss: 0.00866\n",
      "Epoch 1360\n",
      "Loss: 0.95004\n",
      "Epoch 1380\n",
      "Loss: 0.00346\n",
      "Epoch 1400\n",
      "Loss: 0.45014\n",
      "Epoch 1420\n",
      "Loss: 0.04261\n",
      "Epoch 1440\n",
      "Loss: 0.00763\n",
      "Epoch 1460\n",
      "Loss: 0.00695\n",
      "Epoch 1480\n",
      "Loss: 0.60746\n",
      "Epoch 1500\n",
      "Loss: 0.69402\n",
      "Epoch 1520\n",
      "Loss: 0.01862\n",
      "Epoch 1540\n",
      "Loss: 0.12568\n",
      "Epoch 1560\n",
      "Loss: 0.01398\n",
      "Epoch 1580\n",
      "Loss: 0.00636\n",
      "Epoch 1600\n",
      "Loss: 0.32225\n",
      "Epoch 1620\n",
      "Loss: 0.03707\n",
      "Epoch 1640\n",
      "Loss: 0.01995\n",
      "Epoch 1660\n",
      "Loss: 0.10641\n",
      "Epoch 1680\n",
      "Loss: 0.00713\n",
      "Epoch 1700\n",
      "Loss: 0.85421\n",
      "Epoch 1720\n",
      "Loss: 0.03546\n",
      "Epoch 1740\n",
      "Loss: 0.02285\n",
      "Epoch 1760\n",
      "Loss: 0.12919\n",
      "Epoch 1780\n",
      "Loss: 0.10665\n",
      "Epoch 1800\n",
      "Loss: 0.51104\n",
      "Epoch 1820\n",
      "Loss: 0.01839\n",
      "Epoch 1840\n",
      "Loss: 0.00896\n",
      "Epoch 1860\n",
      "Loss: 0.32820\n",
      "Epoch 1880\n",
      "Loss: 0.00246\n",
      "Epoch 1900\n",
      "Loss: 0.05075\n",
      "Epoch 1920\n",
      "Loss: 0.55921\n",
      "Epoch 1940\n",
      "Loss: 0.00452\n",
      "Epoch 1960\n",
      "Loss: 0.01645\n",
      "Epoch 1980\n",
      "Loss: 0.00838\n",
      "Epoch 2000\n",
      "Loss: 0.00285\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "batch_size = 64\n",
    "\n",
    "for i in range(2000):\n",
    "    \n",
    "    sequence = np.random.random_integers(0, 9, (input_sequence_size, batch_size))\n",
    "    sequence_size = np.random.random_integers(1, input_sequence_size)\n",
    "    sequence[sequence_size:, :] = Symbol.END\n",
    "    sequence_size = np.array([sequence_size] * batch_size)\n",
    "    \n",
    "    feeds = {first_term: sequence, first_term_size: sequence_size}\n",
    "\n",
    "    _, loss_value = sess.run([train_op, loss], feed_dict=feeds)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        loss_value /= sequence_size[0]\n",
    "        print('Epoch %d' % (i + 1))\n",
    "        print('Loss: %.5f' % loss_value)\n",
    "\n",
    "sample_sequence = np.random.random_integers(0, 9, (20, 1))\n",
    "test_feeds = {sample_input: sample_sequence, sample_size: [6]}\n",
    "np_encoded_state = sess.run([sample_encoder_state], feed_dict=test_feeds)[0]\n",
    "\n",
    "chosen_digit = [Symbol.GO]\n",
    "answer = []\n",
    "\n",
    "while len(answer) < max_sample_size:\n",
    "    decoder_feeds = {sample_decoder_input: [chosen_digit],\n",
    "                     sample_decoder_state: np_encoded_state}\n",
    "    np_softmax, np_encoded_state = sess.run([sample_softmax[0], new_decoder_state],\n",
    "                                             feed_dict=decoder_feeds)\n",
    "    chosen_digit = np_softmax.argmax(1)\n",
    "    \n",
    "    if chosen_digit == Symbol.END:\n",
    "        break\n",
    "    else:\n",
    "        answer.append(chosen_digit)\n",
    "    \n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 1 6 7 5 8 1 1 1 9 3 7 6 8 1 3 0 9 6]\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4]), array([3]), array([1]), array([6]), array([7]), array([5])]\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
